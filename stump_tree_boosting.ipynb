{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lAlowAPy4C0"
   },
   "source": [
    "# Implementação do Algoritmo de Boosting (Stump Tree Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "c8fJYPYdy2fU",
    "outputId": "95c07641-521f-47f6-db5c-a4e269104a98"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Q1','Q2','Q3','Q4','Q5','Q6','Q7','Q8','Q9', 'XResult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "z_rGef7qMDYU",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('tic-tac-toe.data', names=columns, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>XResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9   XResult\n",
       "0  x  x  x  x  o  o  x  o  o  positive\n",
       "1  x  x  x  x  o  o  o  x  o  positive\n",
       "2  x  x  x  x  o  o  o  o  x  positive\n",
       "3  x  x  x  x  o  o  o  b  b  positive\n",
       "4  x  x  x  x  o  o  b  o  b  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tratando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lidando com campos não númericos\n",
    "    - \"positive\" vira 1\n",
    "    - \"negative\" vira -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(\"positive\", 1, regex=True)\n",
    "data = data.replace(\"negative\", -1, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(\"x\", 1, regex=True)\n",
    "data = data.replace(\"o\", -1, regex=True)\n",
    "data = data.replace(\"b\", 0, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>XResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  XResult\n",
       "0   1   1   1   1  -1  -1   1  -1  -1        1\n",
       "1   1   1   1   1  -1  -1  -1   1  -1        1\n",
       "2   1   1   1   1  -1  -1  -1  -1   1        1\n",
       "3   1   1   1   1  -1  -1  -1   0   0        1\n",
       "4   1   1   1   1  -1  -1   0  -1   0        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separando `Features` de `Target Output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data = data.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1,  1, -1, -1,  1, -1, -1],\n",
       "       [ 1,  1,  1,  1, -1, -1, -1,  1, -1],\n",
       "       [ 1,  1,  1,  1, -1, -1, -1, -1,  1],\n",
       "       [ 1,  1,  1,  1, -1, -1, -1,  0,  0],\n",
       "       [ 1,  1,  1,  1, -1, -1,  0, -1,  0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_data.head().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_data = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data.head().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Estabelecendo conjuntos treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dividimos \"feature\" e \"output\" em treino(80%) e teste(20%), de forma aleatória:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_data.values\n",
    "y = output_data.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  0, -1,  0, -1,  0,  0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Implementação de Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificação binária:\n",
    "- Nossas features são o estado dos quadrantes, o estado do tabuleiro, podendo conter X, O ou B (vazio)\n",
    "- Nossa output é +1 se X ganhou, -1 se X não ganhou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Funções auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo em vista a baixa complexidade do problema e a quantidade baixa de features, produziremos de antemão um grupo de  com todas as possiblidades de Stumps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os stumps contém informação sobre a feature que consideram, o valor que vão verificar se a feature se iguala e a predição (-1, 1) feita quando for verificada igualdade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStump(splittingFeature, value, prediction):\n",
    "    stump = {'splittingFeature' : splittingFeature,\n",
    "             'value'            : value,\n",
    "             'prediction'       : prediction}\n",
    "    return stump "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A stump pool consiste no grupo com todas as possibilidades p/ Stumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStumpPool(features,values):\n",
    "    stumpPool = []\n",
    "    \n",
    "    stumpPool.append(createStump(None,None,1))\n",
    "    stumpPool.append(createStump(None,None,-1))\n",
    "    \n",
    "    for v in values:\n",
    "        for f in features:\n",
    "            stumpPool.append(createStump(f,v,1))\n",
    "            stumpPool.append(createStump(f,v,-1))\n",
    "    \n",
    "    return stumpPool        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função classify() faz as predições dados um stump e um grupo de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(stump, X):\n",
    "    yPred = np.zeros((len(X)))\n",
    "    for i in range (len(X)):\n",
    "        yPred[i] = stump['prediction']\n",
    "        if (stump['splittingFeature'] != None):       \n",
    "            if (int(X[i][stump['splittingFeature']]) == stump['value']):\n",
    "                yPred[i] = stump['prediction']\n",
    "            else:\n",
    "                yPred[i] = -(stump['prediction'])\n",
    "    return yPred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo temos uma função para evocar classify para todos os stumps da pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poolClassify(stumpPool, X):\n",
    "#     y = np.zeros((len stumpPool, len(X)))\n",
    "    yLists = []\n",
    "    for s in  range(len(stumpPool)):\n",
    "        cl = classify(stumpPool[s],X)\n",
    "        yLists.append(cl)\n",
    "    return yLists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função _predictionMissIndexes()_ abaixo verifica e retorna índices de acerto e de erro no vetor de previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predictionMissIndexes(yPred, yTarget):\n",
    "    miss = []\n",
    "    hit = []\n",
    "    for i in range (len(yPred)):\n",
    "        if yPred[i] != int(yTarget[i]):\n",
    "            miss.append(i)      \n",
    "        else:\n",
    "            hit.append(i)      \n",
    "    return miss, hit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_MissIndexesCollection()_ abaixo evoca _predictionMissIndexes()_ para todos os stumps da pool, tendo em vista que suas listas de predição estão compiladas em yPredList."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missIndexesCollection(yPredList, yTarget):\n",
    "    missCollection = []\n",
    "    hitCollection = []\n",
    "    for i in range (len(yPredList)):\n",
    "        miss, hit = predictionMissIndexes(yPredList[i], yTarget)\n",
    "        missCollection.append(miss)    \n",
    "        hitCollection.append(hit)\n",
    "    return missCollection, hitCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_PredictionErrorScore()_ calcula o erro ponderado da previsão, isto é, soma e retorna os pesos das previsões erradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionErrorScore(dataWeight, miss):\n",
    "    error = 0\n",
    "    for i in miss:\n",
    "        error += dataWeight[i]\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_ErrorRate()_ calcula o erro não ponderado, baseado apenas na quantia de erros e na quantidade de amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorRate(X, miss):\n",
    "    return len(miss)/len(X)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_pickBestStump()_ é a função que encontra e retorna o melhor stump dada uma configuração dos pesos. Baseia-se no erro ponderado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickBestStump(miss, dataWeight):\n",
    "    bestStumpIdx  = 0\n",
    "    minErrorVal = 1 \n",
    "    \n",
    "    for i in range(len(miss)):\n",
    "        currError = predictionErrorScore(dataWeight, miss[i])\n",
    "        if(currError < minErrorVal):\n",
    "            minErrorVal = currError\n",
    "            bestStumpIdx = i\n",
    "    \n",
    "    return bestStumpIdx, minErrorVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Algoritmo de boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Função de geração do classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliada pelas funções apresentadas anteriormente, abaixo temos a nossa função de boosting. A função treina um classificador, dado pela combinação de _ensemble e alphas_, isto é, da escolha de stumps associada a um peso alpha.\n",
    "\n",
    "A função recebe:\n",
    "- X : features\n",
    "- y : target\n",
    "- featureColumns : índice das colunas das features que serão usadas\n",
    "- featurePossibleValues : valores que as features podem assumir (-1, 0 e 1; anteriormente o, b, x)\n",
    "    - Optamos por usar esse parâmetro para viabilizar a estratégia de geração prévia dos stumps, considerando a baixa complexidade do conjunto de dados com que estamos trabalhando neste trabalho prático.\n",
    "- iterations : quantidade de iterações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDetails(iteration, epsilon, alpha, bestStump, weights):\n",
    "    print(\"-------------- Iteration \",iteration, \"--------------\")\n",
    "    print(\"cur. weights sample: \", weights)\n",
    "    print(\"BestStump: \", bestStump)\n",
    "    print(\"Epsilon: \", epsilon)\n",
    "    print(\"Alpha: \", alpha)\n",
    "    print(\"------------------------------------------\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boosting(X, y, featureColumns, featurePossibleValues, iterations, printing = False):\n",
    "    dataWeight = np.full((len(X)), 1/len(X), dtype=float) \n",
    "    alphas = np.zeros((iterations))\n",
    "    stumpPool = createStumpPool(featureColumns, featurePossibleValues)\n",
    "    y_pred_lists = poolClassify(stumpPool, X)    \n",
    "    missCollection, hitCollection = missIndexesCollection(y_pred_lists, y)\n",
    "    \n",
    "    ensemble = []\n",
    "    for i in range(iterations):\n",
    "        #Escolhe o melhor stump e calcula seu epsilon\n",
    "        bestStumpIdx,epsilon = pickBestStump(missCollection, dataWeight)\n",
    "        \n",
    "        #Calcula alpha da iteração atual\n",
    "        alphas[i] = 0.5 * log((1-epsilon)/float(epsilon))\n",
    "               \n",
    "        if printing: printDetails(i, epsilon, alphas[i], stumpPool[bestStumpIdx], dataWeight[:12])    \n",
    "            \n",
    "        #Recalcula pesos para os casos de erro e acerto\n",
    "        for j in missCollection[bestStumpIdx]:\n",
    "            dataWeight[j] = dataWeight[j]*exp(alphas[i])\n",
    "        \n",
    "        for k in hitCollection[bestStumpIdx]:\n",
    "            dataWeight[k] = dataWeight[k]*exp(-alphas[i])\n",
    "        \n",
    "        #Regularizador para tornar soma dos pesos = 1\n",
    "        dataWeight = dataWeight / float(dataWeight.sum())\n",
    "        ensemble.append(stumpPool[bestStumpIdx])\n",
    "    return ensemble, alphas\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Função de predição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A predição ocorre da seguinte forma:\n",
    "- Caso a soma das predições dos stumps (ponderadas pelo alpha correspondente):\n",
    "    - resultem em um valor > 0: predição  = 1\n",
    "    - resultem em um valor <= 0: predição = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(alphas, ensemble, X):\n",
    "    \n",
    "    yPredLists = poolClassify(ensemble, X);\n",
    "    yPred = np.zeros((len(yPredLists[0])))\n",
    "    \n",
    "    for i in range(len(yPredLists)):        \n",
    "        yPredLists[i] = yPredLists[i] * alphas[i] \n",
    "        yPred += yPredLists[i]\n",
    "    \n",
    "    for j in range(len(yPred)):\n",
    "        if(yPred[j] > 0):\n",
    "            yPred[j] = 1\n",
    "        else:\n",
    "            yPred[j] = -1\n",
    "\n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Validação cruzada 5-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validação cruzada k-fold foi implementada manualmente, podendo ser executada nas células abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método para a partição de conjuntos de treino e teste, dentro da fase de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldcv(indices, k = 5, seed = 42):\n",
    "    size = len(indices)\n",
    "    subset_size = round(size / k)\n",
    "    random.Random(seed).shuffle(indices)\n",
    "    subsets = [indices[x:x+subset_size] for x in range(0, len(indices), subset_size)]\n",
    "    kfolds = []\n",
    "    for i in range(k):\n",
    "        test = subsets[i]\n",
    "        train = []\n",
    "        for subset in subsets:\n",
    "            if subset != test:\n",
    "                train += subset\n",
    "        kfolds.append((train,test))\n",
    "        \n",
    "    return kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ix = list(range(len(X_train)))\n",
    "kfolds = kfoldcv(ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o intuito de comparar o desempenho do classificador para variações do parâmetro _iterations_, realizamos múltiplas execuções. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 14,\n",
       " 16,\n",
       " 18,\n",
       " 20,\n",
       " 22,\n",
       " 24,\n",
       " 26,\n",
       " 28,\n",
       " 30,\n",
       " 32,\n",
       " 34,\n",
       " 36,\n",
       " 38,\n",
       " 40,\n",
       " 42,\n",
       " 44,\n",
       " 46,\n",
       " 48,\n",
       " 50,\n",
       " 52,\n",
       " 54,\n",
       " 56,\n",
       " 58,\n",
       " 60,\n",
       " 62,\n",
       " 64,\n",
       " 66,\n",
       " 68,\n",
       " 70,\n",
       " 72,\n",
       " 74,\n",
       " 76,\n",
       " 78,\n",
       " 80,\n",
       " 82,\n",
       " 84,\n",
       " 86,\n",
       " 88,\n",
       " 90,\n",
       " 92,\n",
       " 94,\n",
       " 96,\n",
       " 98,\n",
       " 100,\n",
       " 102,\n",
       " 104,\n",
       " 106,\n",
       " 108,\n",
       " 110,\n",
       " 112,\n",
       " 114,\n",
       " 116,\n",
       " 118,\n",
       " 120,\n",
       " 122,\n",
       " 124,\n",
       " 126,\n",
       " 128,\n",
       " 130,\n",
       " 132,\n",
       " 134,\n",
       " 136,\n",
       " 138,\n",
       " 140,\n",
       " 142,\n",
       " 144,\n",
       " 146,\n",
       " 148,\n",
       " 150,\n",
       " 152,\n",
       " 154,\n",
       " 156,\n",
       " 158,\n",
       " 160,\n",
       " 162,\n",
       " 164,\n",
       " 166,\n",
       " 168,\n",
       " 170,\n",
       " 172,\n",
       " 174,\n",
       " 176,\n",
       " 178,\n",
       " 180,\n",
       " 182,\n",
       " 184,\n",
       " 186,\n",
       " 188,\n",
       " 190,\n",
       " 192,\n",
       " 194,\n",
       " 196,\n",
       " 198,\n",
       " 200,\n",
       " 202,\n",
       " 204,\n",
       " 206,\n",
       " 208,\n",
       " 210,\n",
       " 212,\n",
       " 214,\n",
       " 216,\n",
       " 218,\n",
       " 220,\n",
       " 222,\n",
       " 224,\n",
       " 226,\n",
       " 228,\n",
       " 230,\n",
       " 232,\n",
       " 234,\n",
       " 236,\n",
       " 238,\n",
       " 240,\n",
       " 242,\n",
       " 244,\n",
       " 246,\n",
       " 248,\n",
       " 250,\n",
       " 252,\n",
       " 254]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterationsGrid = list(range(128))\n",
    "iterationsGrid = [element * 2 for element in iterationsGrid]\n",
    "iterationsGrid[0] = 1\n",
    "iterationsGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  iteractions - M. Accuracy score: 0.7243066884176182\n",
      "2  iteractions - M. Accuracy score: 0.7243066884176182\n",
      "4  iteractions - M. Accuracy score: 0.734094616639478\n",
      "6  iteractions - M. Accuracy score: 0.7357259380097879\n",
      "8  iteractions - M. Accuracy score: 0.7455138662316476\n",
      "10  iteractions - M. Accuracy score: 0.7797716150081566\n",
      "12  iteractions - M. Accuracy score: 0.7814029363784666\n",
      "14  iteractions - M. Accuracy score: 0.7928221859706363\n",
      "16  iteractions - M. Accuracy score: 0.7814029363784666\n",
      "18  iteractions - M. Accuracy score: 0.7830342577487766\n",
      "20  iteractions - M. Accuracy score: 0.7944535073409462\n",
      "22  iteractions - M. Accuracy score: 0.800978792822186\n",
      "24  iteractions - M. Accuracy score: 0.7846655791190864\n",
      "26  iteractions - M. Accuracy score: 0.7862969004893964\n",
      "28  iteractions - M. Accuracy score: 0.7944535073409462\n",
      "30  iteractions - M. Accuracy score: 0.8075040783034257\n",
      "32  iteractions - M. Accuracy score: 0.8140293637846656\n",
      "34  iteractions - M. Accuracy score: 0.8058727569331158\n",
      "36  iteractions - M. Accuracy score: 0.8172920065252854\n",
      "38  iteractions - M. Accuracy score: 0.8270799347471451\n",
      "40  iteractions - M. Accuracy score: 0.8254486133768353\n",
      "42  iteractions - M. Accuracy score: 0.8189233278955954\n",
      "44  iteractions - M. Accuracy score: 0.8238172920065253\n",
      "46  iteractions - M. Accuracy score: 0.8238172920065253\n",
      "48  iteractions - M. Accuracy score: 0.833605220228385\n",
      "50  iteractions - M. Accuracy score: 0.8548123980424144\n",
      "52  iteractions - M. Accuracy score: 0.8515497553017944\n",
      "54  iteractions - M. Accuracy score: 0.8531810766721044\n",
      "56  iteractions - M. Accuracy score: 0.8515497553017944\n",
      "58  iteractions - M. Accuracy score: 0.8564437194127243\n",
      "60  iteractions - M. Accuracy score: 0.8694942903752039\n",
      "62  iteractions - M. Accuracy score: 0.8548123980424144\n",
      "64  iteractions - M. Accuracy score: 0.8531810766721044\n",
      "66  iteractions - M. Accuracy score: 0.8629690048939641\n",
      "68  iteractions - M. Accuracy score: 0.8711256117455138\n",
      "70  iteractions - M. Accuracy score: 0.8694942903752039\n",
      "72  iteractions - M. Accuracy score: 0.8727569331158238\n",
      "74  iteractions - M. Accuracy score: 0.8613376835236541\n",
      "76  iteractions - M. Accuracy score: 0.8743882544861338\n",
      "78  iteractions - M. Accuracy score: 0.867862969004894\n",
      "80  iteractions - M. Accuracy score: 0.8858075040783034\n",
      "82  iteractions - M. Accuracy score: 0.8792822185970636\n",
      "84  iteractions - M. Accuracy score: 0.8841761827079935\n",
      "86  iteractions - M. Accuracy score: 0.8841761827079935\n",
      "88  iteractions - M. Accuracy score: 0.8890701468189234\n",
      "90  iteractions - M. Accuracy score: 0.8955954323001631\n",
      "92  iteractions - M. Accuracy score: 0.9135399673735726\n",
      "94  iteractions - M. Accuracy score: 0.9037520391517129\n",
      "96  iteractions - M. Accuracy score: 0.9021207177814029\n",
      "98  iteractions - M. Accuracy score: 0.9004893964110929\n",
      "100  iteractions - M. Accuracy score: 0.9021207177814029\n",
      "102  iteractions - M. Accuracy score: 0.9086460032626428\n",
      "104  iteractions - M. Accuracy score: 0.9135399673735726\n",
      "106  iteractions - M. Accuracy score: 0.9314845024469821\n",
      "108  iteractions - M. Accuracy score: 0.9233278955954323\n",
      "110  iteractions - M. Accuracy score: 0.9151712887438825\n",
      "112  iteractions - M. Accuracy score: 0.9200652528548124\n",
      "114  iteractions - M. Accuracy score: 0.9282218597063622\n",
      "116  iteractions - M. Accuracy score: 0.933115823817292\n",
      "118  iteractions - M. Accuracy score: 0.9314845024469821\n",
      "120  iteractions - M. Accuracy score: 0.9216965742251223\n",
      "122  iteractions - M. Accuracy score: 0.9347471451876019\n",
      "124  iteractions - M. Accuracy score: 0.9347471451876019\n",
      "126  iteractions - M. Accuracy score: 0.9363784665579119\n",
      "128  iteractions - M. Accuracy score: 0.9380097879282219\n",
      "130  iteractions - M. Accuracy score: 0.9445350734094616\n",
      "132  iteractions - M. Accuracy score: 0.9412724306688418\n",
      "134  iteractions - M. Accuracy score: 0.9461663947797716\n",
      "136  iteractions - M. Accuracy score: 0.9494290375203915\n",
      "138  iteractions - M. Accuracy score: 0.9543230016313213\n",
      "140  iteractions - M. Accuracy score: 0.9624796084828712\n",
      "142  iteractions - M. Accuracy score: 0.9559543230016313\n",
      "144  iteractions - M. Accuracy score: 0.9494290375203915\n",
      "146  iteractions - M. Accuracy score: 0.9526916802610114\n",
      "148  iteractions - M. Accuracy score: 0.9510603588907015\n",
      "150  iteractions - M. Accuracy score: 0.9526916802610114\n",
      "152  iteractions - M. Accuracy score: 0.9608482871125612\n",
      "154  iteractions - M. Accuracy score: 0.965742251223491\n",
      "156  iteractions - M. Accuracy score: 0.965742251223491\n",
      "158  iteractions - M. Accuracy score: 0.965742251223491\n",
      "160  iteractions - M. Accuracy score: 0.9738988580750407\n",
      "162  iteractions - M. Accuracy score: 0.9722675367047309\n",
      "164  iteractions - M. Accuracy score: 0.965742251223491\n",
      "166  iteractions - M. Accuracy score: 0.964110929853181\n",
      "168  iteractions - M. Accuracy score: 0.9706362153344209\n",
      "170  iteractions - M. Accuracy score: 0.9624796084828712\n",
      "172  iteractions - M. Accuracy score: 0.9706362153344209\n",
      "174  iteractions - M. Accuracy score: 0.967373572593801\n",
      "176  iteractions - M. Accuracy score: 0.9755301794453507\n",
      "178  iteractions - M. Accuracy score: 0.9771615008156607\n",
      "180  iteractions - M. Accuracy score: 0.9787928221859706\n",
      "182  iteractions - M. Accuracy score: 0.9771615008156607\n",
      "184  iteractions - M. Accuracy score: 0.9755301794453507\n",
      "186  iteractions - M. Accuracy score: 0.9771615008156607\n",
      "188  iteractions - M. Accuracy score: 0.9755301794453507\n",
      "190  iteractions - M. Accuracy score: 0.9722675367047309\n",
      "192  iteractions - M. Accuracy score: 0.9755301794453507\n",
      "194  iteractions - M. Accuracy score: 0.9690048939641109\n",
      "196  iteractions - M. Accuracy score: 0.9690048939641109\n",
      "198  iteractions - M. Accuracy score: 0.9706362153344209\n",
      "200  iteractions - M. Accuracy score: 0.9787928221859706\n",
      "202  iteractions - M. Accuracy score: 0.9771615008156607\n",
      "204  iteractions - M. Accuracy score: 0.9771615008156607\n",
      "206  iteractions - M. Accuracy score: 0.9771615008156607\n",
      "208  iteractions - M. Accuracy score: 0.9755301794453507\n",
      "210  iteractions - M. Accuracy score: 0.9771615008156607\n",
      "212  iteractions - M. Accuracy score: 0.9804241435562806\n",
      "214  iteractions - M. Accuracy score: 0.9787928221859706\n",
      "216  iteractions - M. Accuracy score: 0.9787928221859706\n",
      "218  iteractions - M. Accuracy score: 0.9787928221859706\n",
      "220  iteractions - M. Accuracy score: 0.9820554649265906\n",
      "222  iteractions - M. Accuracy score: 0.9804241435562806\n",
      "224  iteractions - M. Accuracy score: 0.9804241435562806\n",
      "226  iteractions - M. Accuracy score: 0.9804241435562806\n",
      "228  iteractions - M. Accuracy score: 0.9771615008156607\n",
      "230  iteractions - M. Accuracy score: 0.9804241435562806\n",
      "232  iteractions - M. Accuracy score: 0.9804241435562806\n",
      "234  iteractions - M. Accuracy score: 0.9804241435562806\n",
      "236  iteractions - M. Accuracy score: 0.9804241435562806\n",
      "238  iteractions - M. Accuracy score: 0.9820554649265906\n",
      "240  iteractions - M. Accuracy score: 0.9820554649265906\n",
      "242  iteractions - M. Accuracy score: 0.9804241435562806\n",
      "244  iteractions - M. Accuracy score: 0.9787928221859706\n",
      "246  iteractions - M. Accuracy score: 0.9804241435562806\n",
      "248  iteractions - M. Accuracy score: 0.9820554649265906\n",
      "250  iteractions - M. Accuracy score: 0.9836867862969005\n",
      "252  iteractions - M. Accuracy score: 0.9820554649265906\n",
      "254  iteractions - M. Accuracy score: 0.9804241435562806\n"
     ]
    }
   ],
   "source": [
    "cvScores = []\n",
    "for n in iterationsGrid:\n",
    "    meanAccuracy = 0;\n",
    "    for i in range(5):\n",
    "        ensemble_, alphas_ = boosting(X_train[kfolds[i][0]], y_train[kfolds[i][0]], [0,1,2,3,4,5,6,7,8], [-1,0,1], n)\n",
    "        y_pred_ = predict(alphas_, ensemble_, X_train[kfolds[i][0]])\n",
    "        meanAccuracy = meanAccuracy + metrics.accuracy_score(y_train[kfolds[i][0]], y_pred_)\n",
    "    meanAccuracy = meanAccuracy/5 \n",
    "    cvScores.append(meanAccuracy)\n",
    "    \n",
    "    print(n,\" iteractions - M. Accuracy score:\",metrics.accuracy_score(y_train[kfolds[i][0]], y_pred_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efetuando validação cruzada 5-fold, com base no score de acurácia, juntamente à variação do parâmetro do número de iterações, obtivemos o gráfico abaixo, que nos revela a evolução e melhora do modelo com o aumento das iterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = 7, 5\n",
    "plt.plot(iterationsGrid, cvScores, '-', linewidth=4.0, label='Training Accuracy')\n",
    "plt.title('Accuracy on 5-fold Cross-validation')\n",
    "plt.xlabel('# of iterations')\n",
    "plt.ylabel('Classification error')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir os resultados obtidos acima, observamos que o modelo mostrou-se robusto à overfitting, de forma com que podemos utilizar valores bastante altos para o número de iterações e atingir resultados muito bons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1 Exemplo: observando as iterações durante o boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, vamos treinar um modelo mais simples, com menor número de iterações, mas apresentando prints sobre o estado do boosting iterativamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostraremos, para cada iteração, alguns valores relevantes:\n",
    "- Uma parte dos pesos para cada amostra\n",
    "- O melhor stump p/ iteração \n",
    "- O valor de epsilon (erro ponderado)\n",
    "- O valor de alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Iteration  0 --------------\n",
      "cur. weights sample:  [0.00130548 0.00130548 0.00130548 0.00130548 0.00130548 0.00130548\n",
      " 0.00130548 0.00130548 0.00130548 0.00130548 0.00130548 0.00130548]\n",
      "BestStump:  {'splittingFeature': 4, 'value': -1, 'prediction': -1}\n",
      "Epsilon:  0.2845953002610977\n",
      "Alpha:  0.4608901120794606\n",
      "------------------------------------------\n",
      "-------------- Iteration  1 --------------\n",
      "cur. weights sample:  [0.00091241 0.00091241 0.00229358 0.00229358 0.00091241 0.00091241\n",
      " 0.00091241 0.00091241 0.00091241 0.00229358 0.00091241 0.00091241]\n",
      "BestStump:  {'splittingFeature': 8, 'value': -1, 'prediction': -1}\n",
      "Epsilon:  0.35760563851871635\n",
      "Alpha:  0.29288578723923164\n",
      "------------------------------------------\n",
      "-------------- Iteration  2 --------------\n",
      "cur. weights sample:  [0.00071016 0.00127572 0.00178518 0.00320685 0.00071016 0.00071016\n",
      " 0.00071016 0.00071016 0.00071016 0.00178518 0.00071016 0.00071016]\n",
      "BestStump:  {'splittingFeature': 2, 'value': -1, 'prediction': -1}\n",
      "Epsilon:  0.35984745285084246\n",
      "Alpha:  0.2880131516535692\n",
      "------------------------------------------\n",
      "-------------- Iteration  3 --------------\n",
      "cur. weights sample:  [0.00098675 0.00099642 0.00139434 0.00445585 0.00055468 0.00055468\n",
      " 0.00098675 0.00055468 0.00098675 0.00139434 0.00055468 0.00098675]\n",
      "BestStump:  {'splittingFeature': 0, 'value': -1, 'prediction': -1}\n",
      "Epsilon:  0.3679492319402256\n",
      "Alpha:  0.2705123740806402\n",
      "------------------------------------------\n",
      "Wall time: 78.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ensemble, alphas = boosting(X_train, y_train, [0,1,2,3,4,5,6,7,8], [-1,0,1], n_iter, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2 Treino definitivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo abaixo, realizaremos o treino do modelo com 250 iterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ensemble, alphas = boosting(X_train, y_train, [0,1,2,3,4,5,6,7,8], [-1,0,1], 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 0, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 3, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 7, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 7, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 7, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 3, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 3, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 7, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 0, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 7, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 7, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 3, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 5, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 7, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 5, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 3, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 0, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 5, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 2, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 5, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 6, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 8, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 3, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 5, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 2, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 4, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 8, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 0, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 6, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 5, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 3, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 0, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 1, 'value': 1, 'prediction': 1},\n",
       " {'splittingFeature': 7, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 3, 'value': 0, 'prediction': 1},\n",
       " {'splittingFeature': 2, 'value': -1, 'prediction': -1},\n",
       " {'splittingFeature': 4, 'value': 1, 'prediction': 1}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46089011, 0.29288579, 0.28801315, 0.27051237, 0.25760764,\n",
       "       0.19020913, 0.10801129, 0.1235074 , 0.1205649 , 0.11727477,\n",
       "       0.12259715, 0.12199742, 0.14083052, 0.12534166, 0.11323124,\n",
       "       0.09567063, 0.09918314, 0.0914556 , 0.10214205, 0.09942471,\n",
       "       0.10850814, 0.10952228, 0.10644341, 0.09991602, 0.10515756,\n",
       "       0.09526502, 0.1031139 , 0.08779212, 0.10164823, 0.0918941 ,\n",
       "       0.08451572, 0.09799058, 0.09260305, 0.10632203, 0.09759243,\n",
       "       0.08958991, 0.1005079 , 0.09710042, 0.09548905, 0.09750637,\n",
       "       0.10673145, 0.09348189, 0.0956331 , 0.09396187, 0.09606012,\n",
       "       0.09337823, 0.09749281, 0.09712923, 0.0904344 , 0.0877726 ,\n",
       "       0.09486289, 0.10478936, 0.10080457, 0.09583708, 0.09141681,\n",
       "       0.09578454, 0.09360407, 0.09430311, 0.09940352, 0.0984382 ,\n",
       "       0.09069244, 0.09436484, 0.09357075, 0.09104117, 0.09300992,\n",
       "       0.09441326, 0.09237693, 0.09744705, 0.09558163, 0.10441121,\n",
       "       0.09262383, 0.0954747 , 0.09453582, 0.08894234, 0.09704106,\n",
       "       0.09770523, 0.09158857, 0.09699377, 0.09582041, 0.08524512,\n",
       "       0.09800835, 0.09785276, 0.08504784, 0.08976517, 0.09661276,\n",
       "       0.09254679, 0.09633037, 0.09808221, 0.08020658, 0.08619692,\n",
       "       0.10399654, 0.0983484 , 0.08722934, 0.09712031, 0.08974364,\n",
       "       0.08735224, 0.09441078, 0.09935231, 0.0872268 , 0.09633252,\n",
       "       0.08257026, 0.08811123, 0.09149795, 0.08162335, 0.089738  ,\n",
       "       0.08519192, 0.09870631, 0.08663888, 0.0890486 , 0.10587414,\n",
       "       0.09074068, 0.09274187, 0.09496808, 0.09478168, 0.08800824,\n",
       "       0.09073614, 0.09332893, 0.0815322 , 0.090955  , 0.08843427,\n",
       "       0.0901342 , 0.08919473, 0.08805092, 0.08857452, 0.08860749,\n",
       "       0.09314002, 0.09079158, 0.09272367, 0.09699259, 0.08424563,\n",
       "       0.08897884, 0.08404288, 0.0879916 , 0.09150227, 0.08762223,\n",
       "       0.09470202, 0.07891112, 0.07746135, 0.08947288, 0.08892076,\n",
       "       0.0840924 , 0.0990228 , 0.08276294, 0.08906979, 0.07951422,\n",
       "       0.08053866, 0.08528217, 0.0949827 , 0.0989499 , 0.09172701,\n",
       "       0.08781717, 0.09242947, 0.08713453, 0.0872386 , 0.07978478,\n",
       "       0.0884003 , 0.08748512, 0.09516794, 0.08278732, 0.08084146,\n",
       "       0.0842899 , 0.08461714, 0.08670639, 0.0843244 , 0.0848118 ,\n",
       "       0.08957915, 0.08394054, 0.09900183, 0.07786677, 0.08748138,\n",
       "       0.08875471, 0.07929168, 0.08592897, 0.07972738, 0.09052527,\n",
       "       0.08998842, 0.08622145, 0.0739167 , 0.08277727, 0.08203951,\n",
       "       0.09343191, 0.07882437, 0.08032288, 0.07973787, 0.08536912,\n",
       "       0.08612121, 0.08982216, 0.07848198, 0.08089331, 0.08730991,\n",
       "       0.08406336, 0.08555007, 0.08626148, 0.07467093, 0.08079651,\n",
       "       0.09005674, 0.08371547, 0.08174881, 0.08663777, 0.08084121,\n",
       "       0.08276923, 0.08192212, 0.08671867, 0.09118286, 0.07909298,\n",
       "       0.08125457, 0.08086554, 0.0798916 , 0.08069887, 0.08162961,\n",
       "       0.07783232, 0.07946389, 0.07867661, 0.08116996, 0.08222617,\n",
       "       0.08510239, 0.08465568, 0.08080041, 0.08918336, 0.07508747,\n",
       "       0.08188764, 0.08543709, 0.08252406, 0.08177569, 0.07705166,\n",
       "       0.07310467, 0.07956967, 0.07899338, 0.07257098, 0.0797217 ,\n",
       "       0.0853861 , 0.07964259, 0.08279043, 0.07803306, 0.07711098,\n",
       "       0.07766805, 0.08535839, 0.07930237, 0.07240831, 0.0751151 ,\n",
       "       0.07893249, 0.08069282, 0.07264068, 0.08348021, 0.08781209,\n",
       "       0.07252313, 0.0747164 , 0.0745986 , 0.08571184, 0.07525837])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, testamos nossa partição de testes no modelo treinado acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = predict(alphas, ensemble, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9739583333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TP1 ML",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}